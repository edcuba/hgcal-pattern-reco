{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c07744a",
   "metadata": {},
   "source": [
    "# Pairwise MLP with PU\n",
    "\n",
    "Train a pairwise MLP model in a pile-up environment.\n",
    "\n",
    "## Problem setup\n",
    "\n",
    "The reconstruction process consists of the following steps:\n",
    "\n",
    "### 1. Select tracksters above a certain energy threshold\n",
    "\n",
    "Select high energy trackster we want to run the smoothing around.\n",
    "The energy threshold is a fine-tined parameter, generally, 10 - 50 GeV seems to work well.\n",
    "\n",
    "**Result**: Selected Tracksters\n",
    "\n",
    "\n",
    "### 2. Get tracksters in their cylindrical neighborhood\n",
    "- The cylinder is defined along the axis connecting the trackster barycenter to 0,0,0 and a selected radius (e.g. 10cm)\n",
    "- Result: Trackster Candidates, Candidate Pairs\n",
    "\n",
    "### 3. For each Candidate Pair, decide whether the two tracksters should be connected\n",
    "- For each Trackster Candidate, chose the Selected Trackster with the highest predicted score (likelihood)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79f4a00b",
   "metadata": {},
   "source": [
    "## Data location\n",
    "\n",
    "Set `ds_name` to the dataset name, and point `raw_dir` to the directory containing ntuplized `.root` files.\n",
    "Processed `PyTorch` datasets will be placed in the `data_root` folder. The program will verify if the requested datasets exist already. Make sure the directories exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3afcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"CloseByPion200PU\"\n",
    "raw_dir = \"/home/ecuba/data/CloseByPion200PU\"\n",
    "data_root = \"/home/ecuba/data/processed\"\n",
    "model_dir = \"/home/ecuba/data/models\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76b6a79e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ffdcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'],'size': 12})\n",
    "rc('mathtext',**{'default':'regular'})\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from reco.loss import QualityFocalLoss\n",
    "from reco.dataset_pair import TracksterPairs\n",
    "from reco.training import train_mlp, roc_auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ddaddb1",
   "metadata": {},
   "source": [
    "## Load or process the dataset\n",
    "\n",
    "At least `N_FILES=100` root files is recommended to have a large enough training sample.\n",
    "The following parameters need to be set:\n",
    "- `bigT_e_th`: energy threshold to select tracksters for smoothing\n",
    "- `radius`: radius of the cylinder around the selected tracksters\n",
    "- `pileup`: needs to be set to `true` for pile-up datasets, the selection of the tracksters is limited to ones that overlap with a simtrackster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TracksterPairs(\n",
    "    ds_name,\n",
    "    data_root,\n",
    "    raw_dir,\n",
    "    N_FILES=20,\n",
    "    radius=15,\n",
    "    pileup=True,\n",
    "    bigT_e_th=10,\n",
    ")\n",
    "\n",
    "ds[0][0]\n",
    "ds.x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d2ad144",
   "metadata": {},
   "source": [
    "## Split the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84179ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_threshold = 0.7\n",
    "\n",
    "print(ds.x.shape)\n",
    "print(\"Positive:\", int((ds.y >= decision_threshold).type(torch.int).sum()))\n",
    "print(\"Negative:\", int((ds.y < decision_threshold).type(torch.int).sum()))\n",
    "\n",
    "balance =  float(sum(ds.y > decision_threshold) / len(ds.y))\n",
    "print(f\"dataset balance: {balance*100:.2f}% / {(1-balance)*100:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972263a2-610a-4ca9-8805-b2c6830aa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of the pairs to be left for validation\n",
    "val_set_fraction = 0.1\n",
    "\n",
    "ds_size = len(ds)\n",
    "val_set_size = ds_size // int(1. / val_set_fraction)\n",
    "train_set_size = ds_size - val_set_size\n",
    "train_set, val_set = random_split(ds, [train_set_size, val_set_size])\n",
    "print(f\"Train samples: {len(train_set)}, Validation samples: {len(val_set)}\")\n",
    "\n",
    "train_dl = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_dl = DataLoader(val_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "532cf225",
   "metadata": {},
   "source": [
    "## Model configuration\n",
    "\n",
    "Configure model and training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 101\n",
    "\n",
    "hdim1 = 256\n",
    "hdim2 = 128\n",
    "\n",
    "dropout_pr = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9369f5-eacd-4e6a-a162-d8d8a6829f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.LayerNorm(ds.x.shape[1]),      # normalization as a part of the network\n",
    "    nn.Linear(ds.x.shape[1], hdim1),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(hdim1, hdim2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(hdim2, 1),\n",
    "    nn.Dropout(p=dropout_pr),\n",
    ")\n",
    "model = model.to(device)\n",
    "model_path = f\"{model_dir}/PairWiseMLP.{hdim1}.{hdim2}.{epochs}e-{ds_name}.r{ds.RADIUS}.e{ds.bigT_e_th}.f{ds.N_FILES}.pt\"\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = CosineAnnealingLR(optimizer, epochs, eta_min=1e-5)\n",
    "loss_obj = QualityFocalLoss(gamma=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0085bfbb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = train_mlp(model, device, optimizer, train_dl, loss_obj)\n",
    "    train_auc = roc_auc(model, device, train_dl)\n",
    "    val_auc = roc_auc(model, device, val_dl)\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, loss: {loss:.4f}, train auc: {train_auc:.4f}, val auc: {val_auc:.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93072e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    model_path,\n",
    "    map_location=device\n",
    "))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57db4c6-0436-44f9-ab2b-19109c7aced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc(model, device, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_recall_curve(model, device, val_dl, step=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24c40163",
   "metadata": {},
   "source": [
    "# ONNX export\n",
    "\n",
    "Export the trained model into ONNX and verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_filepath = f\"{model_dir}/PairWiseMLP.{hdim1}.{hdim2}.{epochs}e-{ds_name}.{ds.RADIUS}.{ds.SCORE_THRESHOLD}.{ds.N_FILES}f.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,                      # model to be exported\n",
    "    ds[0][0].reshape(1, -1),    # example input (add batch dimension)\n",
    "    onnx_filepath,\n",
    "    export_params=True,\n",
    "    opset_version=10,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['features'],      # the model's input names\n",
    "    output_names=['output'],    # the model's output names\n",
    "    dynamic_axes={              # variable length axes\n",
    "        'features' : {0 : 'batch_size'},    \n",
    "        'output' : {0 : 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(onnx_filepath)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(ds[:16][0])}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "torch_out = model(ds[:16][0])\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f364820",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reco.data import get_event_data\n",
    "from reco.evaluation import model_evaluation\n",
    "from reco.dummy import DummyPleaser\n",
    "\n",
    "file_name = f\"{raw_dir}/test/test_samples_1.root\"\n",
    "cluster_data, trackster_data, simtrackster_data, assoc_data = get_event_data(file_name, pileup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a639dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ranges = [3, 5, 10, 15]\n",
    "results = []\n",
    "\n",
    "max_events = 10\n",
    "clue3D_F = []\n",
    "target_F = []\n",
    "naive_reco_F = []\n",
    "model_reco_F = []\n",
    "for r in r_ranges:\n",
    "    print(f\" --- Radius threshold: {r} ---\")\n",
    "    result = model_evaluation(\n",
    "        cluster_data,\n",
    "        trackster_data,\n",
    "        simtrackster_data,\n",
    "        assoc_data,\n",
    "        DummyPleaser(),\n",
    "        decision_th=decision_threshold,\n",
    "        radius=r,\n",
    "        max_events=max_events,\n",
    "        bigT_e_th=10,\n",
    "        pileup=True\n",
    "    )\n",
    "    clue3D_F.append(np.sum(np.array(result[\"clue3d_to_sim\"])[:,2]) / max_events)\n",
    "    target_F.append(np.sum(np.array(result[\"target_to_sim\"])[:,2]) / max_events)\n",
    "    naive_reco_F.append(np.sum(np.array(result[\"reco_to_sim\"])[:,2]) / max_events)\n",
    "\n",
    "    result = model_evaluation(\n",
    "        cluster_data,\n",
    "        trackster_data,\n",
    "        simtrackster_data,\n",
    "        assoc_data,\n",
    "        model.to(\"cpu\"),\n",
    "        decision_th=decision_threshold,\n",
    "        radius=r,\n",
    "        max_events=max_events,\n",
    "        bigT_e_th=10,\n",
    "        pileup=True\n",
    "    )\n",
    "    model_reco_F.append(np.sum(np.array(result[\"reco_to_sim\"])[:,2]) / max_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4065da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(r_ranges[:6], (np.array(target_F) - np.array(clue3D_F))[:6], '--s', label=\"target\", c=\"#D55E00\")\n",
    "ax.plot(r_ranges[:6], (np.array(model_reco_F) - np.array(clue3D_F))[:6], '-o', label=\"mlp\", c=\"#56B4E9\")\n",
    "ax.plot(r_ranges[:6], (np.array(naive_reco_F) - np.array(clue3D_F))[:6], '-v', label=\"naive\", c=\"#E69F00\")\n",
    "ax.axhline(max(np.array(naive_reco_F) - np.array(clue3D_F)), label=\"baseline\", c=\"lightgray\", linestyle=\"--\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Neighborhood radius (cm)\")\n",
    "ax.set_ylabel(\"$\\Delta F_{0.5}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1176798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
